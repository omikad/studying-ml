{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from IPython import display\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from scipy import stats\n",
    "from training_methods import *\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(env, agent, params, frames):\n",
    "#     img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    state = env_reset(env)\n",
    "    img = plt.imshow(state.reshape(20, 20))   # Pong\n",
    "    frame = 0\n",
    "    for _ in range(frames):\n",
    "#         img.set_data(env.render(mode='rgb_array'))\n",
    "        img.set_data(state.reshape(20, 20))   # Pong\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        action = agent.act_greedy(state, frame)\n",
    "        state, reward, done, _ = env_step(env, action)\n",
    "        if done:\n",
    "            state = env_reset(env)\n",
    "            frame = 0\n",
    "        else:\n",
    "            frame += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LearningParameters:\n",
    "    def __init__(self, env, episodes_count):\n",
    "        state = env_reset(env)\n",
    "\n",
    "        self.state_shape = state.shape\n",
    "        self.state_size = np.prod(self.state_shape)\n",
    "        self.action_size = env.action_space.n\n",
    "        self.episodes_count = episodes_count\n",
    "        self.max_frame_in_episode = env.spec.max_episode_steps\n",
    "        self.max_memory_size = 10000\n",
    "        self.episodes_between_think = 1\n",
    "        \n",
    "        self.gamma = 0.95                # discount rate\n",
    "        self.epsilon = 1.0               # exploration rate\n",
    "        self.epsilon_start = self.epsilon\n",
    "        self.epsilon_min = 0.0001        # min exploration rate\n",
    "        self.learning_rate = 0.1         # learning rate for algorithm\n",
    "        self.learning_rate_model = 0.01  # learning rate for model\n",
    "        \n",
    "        print(\"State shape {}, actions {}\".format(self.state_shape, self.action_size))\n",
    "\n",
    "    def decay_exploration_rate(self, episode):\n",
    "        # Linear exploration rate decay (lerp)\n",
    "#         self.epsilon = self.epsilon_start - \\\n",
    "#                       (self.epsilon_start - self.epsilon_min) * (float(frame) / self.frames_count)\n",
    "            \n",
    "        # Exponential rate decay\n",
    "        # y(0) = start\n",
    "        # y(1) = start * x\n",
    "        # y(2) = start * x^2\n",
    "        # y(steps) = start * x^steps = min => x = (min/start) ^ (1/steps)\n",
    "        # y(t) = start * x^t\n",
    "        self.epsilon = self.epsilon_start * \\\n",
    "                       math.pow( math.pow(self.epsilon_min / self.epsilon_start, 1.0 / self.episodes_count), episode )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action is added to input as OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionAsInputAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        input_len = self.params.state_size + self.params.action_size\n",
    "\n",
    "        x = tf.placeholder(\"float\", [None, input_len], name=\"Placeholder_x\")\n",
    "        y = tf.placeholder(\"float\", [None, 1], name=\"Placeholder_y\")\n",
    "        \n",
    "        w0 = tf.Variable(tf.random_normal([input_len, 20]))\n",
    "        b0 = tf.Variable(tf.random_normal([20]))\n",
    "        w1 = tf.Variable(tf.random_normal([20, 1]))\n",
    "        b1 = tf.Variable(tf.random_normal([1]))\n",
    "        \n",
    "        h0 = tf.add(tf.matmul(x, w0), b0)\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        pred = tf.add(tf.matmul(h0, w1), b1)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(pred - y)\n",
    "        train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99).minimize(cost)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'pred': pred,\n",
    "            'cost': cost,\n",
    "            'train_op': train_op,\n",
    "            'init': init\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state, frame))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        x = self.model['x']\n",
    "        pred = self.model['pred']\n",
    "\n",
    "        X = np.resize(state, (1, self.params.state_size + self.params.action_size))\n",
    "        X[0, self.params.state_size:] = 0\n",
    "        \n",
    "        rewards = np.zeros((self.params.action_size))\n",
    "        for i in range(self.params.action_size):\n",
    "            X[0, self.params.state_size + i] = 1\n",
    "            rewards[i] = session.run(pred, {x: X})[0]\n",
    "            X[0, self.params.state_size + i] = 0\n",
    "        return np.argmax(rewards)\n",
    "    \n",
    "    def think(self, batch_size):\n",
    "        x = self.model['x']\n",
    "        y = self.model['y']\n",
    "        pred = self.model['pred']\n",
    "        train_op = self.model['train_op']\n",
    "        cost = self.model['cost']\n",
    "        \n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size + self.params.action_size))\n",
    "        Y = np.zeros((cnt, 1))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state, frame = self.memory[i]\n",
    "            inp = np.resize(state, (self.params.state_size + self.params.action_size))\n",
    "            inp[self.params.state_size:] = 0\n",
    "            inp[self.params.state_size + action] = 1\n",
    "            X[i], Y[i] = inp, reward\n",
    "\n",
    "        for e in range(1):\n",
    "            P = np.random.permutation(cnt)\n",
    "            for i in range(0, cnt, batch_size):\n",
    "                batch_indexes = P[i: i + batch_size]\n",
    "                batch_x = X[batch_indexes]\n",
    "                batch_y = Y[batch_indexes]\n",
    "                _ = session.run(train_op, {x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient\n",
    "\n",
    "Run with `params.episodes_between_think = 1`\n",
    "\n",
    "Karpathy: https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
    "\n",
    "TF interpretation: https://gist.github.com/greydanus/5036f784eec2036252e1990da21eda18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyGradientAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        x = tf.placeholder(\"float\", [None, self.params.state_size], name='Placeholder_x')\n",
    "        y = tf.placeholder(\"float\", [None, self.params.action_size], name='Placeholder_y')\n",
    "        \n",
    "        w0 = tf.Variable(tf.random_normal([self.params.state_size, 20]))\n",
    "        b0 = tf.Variable(tf.random_normal([20]))\n",
    "        w1 = tf.Variable(tf.random_normal([20, self.params.action_size]))\n",
    "        b1 = tf.Variable(tf.random_normal([self.params.action_size]))\n",
    "        \n",
    "        h0 = tf.add(tf.matmul(x, w0), b0)\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        pred = tf.add(tf.matmul(h0, w1), b1)\n",
    "#         pred = tf.nn.softmax(pred)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(pred - y)\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.params.learning_rate_model, decay=0.99)\n",
    "#         optimizer = tf.train.AdamOptimizer(learning_rate=self.params.learning_rate_model)\n",
    "    \n",
    "        gradients = optimizer.compute_gradients(cost, var_list=tf.trainable_variables())\n",
    "        train_op = optimizer.apply_gradients(gradients)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'pred': pred,\n",
    "            'cost': cost,\n",
    "            'init': init,\n",
    "            'train_op': train_op\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        x = self.model['x']\n",
    "        pred = self.model['pred']\n",
    "        act_values = session.run(pred, feed_dict={x: [state]})[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        x = self.model['x']\n",
    "        y = self.model['y']\n",
    "        pred = self.model['pred']\n",
    "        train_op = self.model['train_op']\n",
    "        \n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size))\n",
    "        Y = np.zeros((cnt, self.params.action_size))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            target = session.run(pred, feed_dict={x: [state]})[0]\n",
    "            target[action] = reward\n",
    "            X[i], Y[i] = state, target\n",
    "\n",
    "        _ = session.run(train_op, {x: X, y: Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DqnAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        x = tf.placeholder(\"float\", [None, self.params.state_size], name=\"Placeholder_x\")\n",
    "        y = tf.placeholder(\"float\", [None, self.params.action_size], name=\"Placeholder_y\")\n",
    "        \n",
    "        w0 = tf.Variable(tf.random_normal([self.params.state_size, 20]))\n",
    "        b0 = tf.Variable(tf.random_normal([20]))\n",
    "        w1 = tf.Variable(tf.random_normal([20, self.params.action_size]))\n",
    "        b1 = tf.Variable(tf.random_normal([self.params.action_size]))\n",
    "        \n",
    "        h0 = tf.add(tf.matmul(x, w0), b0)\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        pred = tf.add(tf.matmul(h0, w1), b1)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(pred - y)\n",
    "        train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99).minimize(cost)\n",
    "#         train_op = tf.train.AdamOptimizer(learning_rate=self.params.learning_rate_model).minimize(cost)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'pred': pred,\n",
    "            'cost': cost,\n",
    "            'init': init,\n",
    "            'train_op': train_op\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        x = self.model['x']\n",
    "        pred = self.model['pred']\n",
    "        act_values = session.run(pred, {x: [state]})[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        x = self.model['x']\n",
    "        y = self.model['y']\n",
    "        pred = self.model['pred']\n",
    "        train_op = self.model['train_op']\n",
    "        cost = self.model['cost']\n",
    "        \n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size))\n",
    "        Y = np.zeros((cnt, self.params.action_size))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            target = session.run(pred, {x: [state]})[0]\n",
    "            target[action] = reward + self.params.gamma * \\\n",
    "                             np.amax(session.run(pred, {x: [next_state]})[0])\n",
    "            X[i], Y[i] = state, target\n",
    "\n",
    "        for e in range(1):\n",
    "            P = np.random.permutation(cnt)\n",
    "            for i in range(0, cnt, batch_size):\n",
    "                batch_indexes = P[i: i + batch_size]\n",
    "                batch_x = X[batch_indexes]\n",
    "                batch_y = Y[batch_indexes]\n",
    "                _ = session.run(train_op, {x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-23 22:08:00,969] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: 6, Observation space (210, 160, 3), 100800 parameters\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input_pong_v0(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I = I[::2,::2,0] + I[1::2,::2,0] + I[::2,1::2,0] + I[1::2,1::2,0]\n",
    "    I = I[::2,::2] + I[1::2,::2] + I[::2,1::2] + I[1::2,1::2]\n",
    "    I = I[::2,::2] + I[1::2,::2] + I[::2,1::2] + I[1::2,1::2]\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "# print(env.spec.max_episode_steps)\n",
    "\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env.my_preprocess_input = lambda x: x\n",
    "\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env.my_preprocess_input = lambda x: x\n",
    "\n",
    "env = gym.make('Pong-v0')\n",
    "env.my_preprocess_input = preprocess_input_pong_v0\n",
    "\n",
    "# env.render(close=True)\n",
    "# plt.imshow(env.render('rgb_array'))\n",
    "print('Actions: {}, Observation space {}, {} parameters'.format(\n",
    "    env.action_space.n, env.observation_space.shape, np.prod(env.observation_space.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(210, 160, 3)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(env.spec.max_episode_steps)\n",
    "state = env.reset()\n",
    "env.step(1)\n",
    "# for i in range(10):\n",
    "#     state, reward, _, _ = env.step(1)\n",
    "# state, reward, _, _ = env.step(2)\n",
    "# state, reward, _, _ = env.step(3)\n",
    "# state, reward, _, _ = env.step(3)\n",
    "print(state.shape)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1224f6650>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h+ORQCnJoHWxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120ecb990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepro(state).reshape((80, 80)).shape\n",
    "plt.imshow(env.my_preprocess_input(state).reshape((80, 80)))\n",
    "# plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape (400,), actions 6\n",
      "episode: 110/2200, reward -9.1, frames 500, exploration rate: 0.64\n",
      "episode: 220/2200, reward -9.2, frames 500, exploration rate: 0.4\n",
      "episode: 330/2200, reward -9.2, frames 500, exploration rate: 0.25\n",
      "episode: 440/2200, reward -9.3, frames 500, exploration rate: 0.16\n",
      "episode: 550/2200, reward -9.2, frames 500, exploration rate: 0.1\n",
      "episode: 660/2200, reward -9.5, frames 500, exploration rate: 0.064\n",
      "episode: 770/2200, reward -9.2, frames 500, exploration rate: 0.04\n",
      "episode: 880/2200, reward -9.3, frames 500, exploration rate: 0.025\n",
      "episode: 990/2200, reward -9.4, frames 500, exploration rate: 0.016\n",
      "episode: 1100/2200, reward -9.2, frames 500, exploration rate: 0.01\n",
      "episode: 1210/2200, reward -9.3, frames 500, exploration rate: 0.0064\n",
      "episode: 1320/2200, reward -9.0, frames 500, exploration rate: 0.004\n",
      "episode: 1430/2200, reward -9.1, frames 500, exploration rate: 0.0025\n",
      "episode: 1540/2200, reward -8.8, frames 500, exploration rate: 0.0016\n",
      "episode: 1650/2200, reward -9.2, frames 500, exploration rate: 0.001\n",
      "episode: 1760/2200, reward -9.0, frames 500, exploration rate: 0.00064\n",
      "episode: 1870/2200, reward -9.1, frames 500, exploration rate: 0.0004\n",
      "episode: 1980/2200, reward -9.2, frames 500, exploration rate: 0.00025\n",
      "episode: 2090/2200, reward -9.1, frames 500, exploration rate: 0.00016\n",
      "episode: 2200/2200, reward -9.0, frames 500, exploration rate: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x127138d50>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhn+P/OMQxOZCpANAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12771f750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = LearningParameters(env, episodes_count=2200)\n",
    "params.max_frame_in_episode = min(params.max_frame_in_episode, 500)\n",
    "\n",
    "# agent = PolicyGradientAgent(params)\n",
    "\n",
    "# agent = DqnAgent(params)\n",
    "\n",
    "# agent = ActionAsInputAgent(params)\n",
    "\n",
    "# if 'session' in locals():\n",
    "#     session.close()\n",
    "# session = tf.Session()\n",
    "# session.run(agent.model['init'])\n",
    "\n",
    "agent, rewards = train_discounted_rewards(env, agent, params, normalize_rewards=True)\n",
    "# agent, rewards = train_reward_is_time(env, agent, params)\n",
    "# agent, rewards = train(env, agent, params)\n",
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -9.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(env, agent, params, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSU0GhKQmA0JS0/8BrEXO86geyxcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127564290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(env, agent, params, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
