{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from IPython import display\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from scipy import stats\n",
    "from training_methods import *\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "run_name = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action is added to input as OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionAsInputAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        input_len = self.params.state_size + self.params.action_size\n",
    "\n",
    "        self.x = tf.placeholder(\"float\", [None, input_len], name=\"Placeholder_x\")\n",
    "        self.y = tf.placeholder(\"float\", [None, 1], name=\"Placeholder_y\")\n",
    "\n",
    "        h0 = tf.contrib.layers.fully_connected(\n",
    "            inputs=self.x,\n",
    "            num_outputs=20,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.pred = tf.contrib.layers.fully_connected(\n",
    "            inputs=h0,\n",
    "            num_outputs=1,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.cost = tf.nn.l2_loss(self.pred - self.y)\n",
    "        self.train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99) \\\n",
    "            .minimize(self.cost)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state, frame))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        X = np.resize(state, (1, self.params.state_size + self.params.action_size))\n",
    "        X[0, self.params.state_size:] = 0\n",
    "        \n",
    "        rewards = np.zeros((self.params.action_size))\n",
    "        for i in range(self.params.action_size):\n",
    "            X[0, self.params.state_size + i] = 1\n",
    "            rewards[i] = session.run(self.pred, {self.x: X})[0]\n",
    "            X[0, self.params.state_size + i] = 0\n",
    "        return np.argmax(rewards)\n",
    "    \n",
    "    def think(self, batch_size, episode):\n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size + self.params.action_size))\n",
    "        Y = np.zeros((cnt, 1))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state, frame = self.memory[i]\n",
    "            inp = np.resize(state, (self.params.state_size + self.params.action_size))\n",
    "            inp[self.params.state_size:] = 0\n",
    "            inp[self.params.state_size + action] = 1\n",
    "            X[i], Y[i] = inp, reward\n",
    "\n",
    "        P = np.random.permutation(cnt)\n",
    "        for i in range(0, cnt, batch_size):\n",
    "            batch_indexes = P[i: i + batch_size]\n",
    "            batch_x = X[batch_indexes]\n",
    "            batch_y = Y[batch_indexes]\n",
    "            _ = session.run(self.train_op, {self.x: batch_x, self.y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient\n",
    "\n",
    "Run with `params.episodes_between_think = 1`\n",
    "\n",
    "Karpathy: https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
    "\n",
    "TF interpretation: https://gist.github.com/greydanus/5036f784eec2036252e1990da21eda18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyGradientAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory_states = []\n",
    "        self.memory_actions = []\n",
    "        self.memory_rewards = []\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.x = tf.placeholder(\"float\", [None, self.params.state_size], name='Placeholder_x')\n",
    "        self.y = tf.placeholder(\"int32\", [None], name='Placeholder_y')\n",
    "        self.r = tf.placeholder(\"float\", [None], name='Placeholder_r')\n",
    "\n",
    "        # Pong:\n",
    "#         x = tf.reshape(self.x, (tf.shape(self.x)[0], 19, 16, 4))\n",
    "#         conv1 = tf.contrib.layers.conv2d(x, 16, 4, 2, activation_fn=tf.nn.relu)\n",
    "#         flattened = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "        # Breakout:\n",
    "        x = tf.reshape(self.x, (tf.shape(self.x)[0], 80, 70, 4))\n",
    "        conv1 = tf.contrib.layers.conv2d(x, 16, 8, 4, activation_fn=tf.nn.relu)\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1, 32, 4, 2, activation_fn=tf.nn.relu)\n",
    "        flattened = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "#         # Cartpole:\n",
    "#         flattened = self.x\n",
    "\n",
    "        fc1 = tf.contrib.layers.fully_connected(flattened, 128,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        fc2 = tf.contrib.layers.fully_connected(\n",
    "            inputs=fc1,\n",
    "            num_outputs=self.params.action_size,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.pred = tf.nn.softmax(fc2)\n",
    "        \n",
    "        actions_ohe = tf.one_hot(self.y, depth=self.params.action_size)\n",
    "        \n",
    "        self.cost = tf.nn.l2_loss(self.pred - actions_ohe)\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.params.learning_rate_model, decay=0.99)\n",
    "    \n",
    "        gradients = optimizer.compute_gradients(\n",
    "            self.cost,\n",
    "            var_list=tf.trainable_variables(),\n",
    "            grad_loss=tf.reshape(self.r, (tf.shape(self.r)[0], 1)))\n",
    "        self.train_op = optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory_states.append(state)\n",
    "        self.memory_actions.append(action)\n",
    "        self.memory_rewards.append(reward)\n",
    "\n",
    "    def act(self, session, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(session, state, frame)\n",
    "    \n",
    "    def act_greedy(self, session, state, frame):\n",
    "        act_values = session.run(self.pred, feed_dict={self.x: [state]})[0]\n",
    "        return np.random.choice(self.params.action_size, p=act_values)\n",
    "\n",
    "    def think(self, session, batch_size, episode):\n",
    "        cnt = len(self.memory_states)\n",
    "\n",
    "        _ = session.run(self.train_op, {\n",
    "            self.x: self.memory_states,\n",
    "            self.y: self.memory_actions,\n",
    "            self.r: self.memory_rewards})\n",
    "        \n",
    "        # It's on-policy algorithm\n",
    "        self.memory_states = [] \n",
    "        self.memory_actions = []\n",
    "        self.memory_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DqnAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory_states = np.zeros((2 * self.params.max_memory_size, self.params.state_size))\n",
    "        self.memory_next_states = np.zeros((2 * self.params.max_memory_size, self.params.state_size))\n",
    "        self.memory_actions = np.zeros((2 * self.params.max_memory_size), dtype=np.int32)\n",
    "        self.memory_rewards = np.zeros((2 * self.params.max_memory_size, 1))\n",
    "        self.cnt = 0\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.x = tf.placeholder(\"float\", [None, self.params.state_size], name=\"Placeholder_x\")\n",
    "        self.y = tf.placeholder(\"float\", [None, self.params.action_size], name=\"Placeholder_y\")\n",
    "\n",
    "        # Pong:\n",
    "#         x = tf.reshape(self.x, (tf.shape(self.x)[0], 19, 16, 4))\n",
    "#         conv1 = tf.contrib.layers.conv2d(x, 16, 4, 2, activation_fn=tf.nn.relu)\n",
    "#         flattened = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "        # Breakout:\n",
    "        x = tf.reshape(self.x, (tf.shape(self.x)[0], 80, 70, 4))\n",
    "        conv1 = tf.contrib.layers.conv2d(x, 16, 8, 4, activation_fn=tf.nn.relu)\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1, 32, 4, 2, activation_fn=tf.nn.relu)\n",
    "        flattened = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Cartpole:\n",
    "#         flattened = self.x\n",
    "\n",
    "        fc1 = tf.contrib.layers.fully_connected(flattened, 128,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.pred = tf.contrib.layers.fully_connected(\n",
    "            inputs=fc1,\n",
    "            num_outputs=self.params.action_size,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "#         self.cost = tf.nn.l2_loss(self.pred - self.y)\n",
    "        self.losses = tf.squared_difference(self.pred, self.y)\n",
    "        self.cost = tf.reduce_mean(self.losses)\n",
    "\n",
    "        self.train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99) \\\n",
    "            .minimize(self.cost)\n",
    "#         train_op = tf.train.AdamOptimizer(learning_rate=self.params.learning_rate_model).minimize(cost)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory_states[self.cnt] = state\n",
    "        self.memory_next_states[self.cnt] = next_state\n",
    "        self.memory_actions[self.cnt] = action\n",
    "        self.memory_rewards[self.cnt] = reward\n",
    "        self.cnt += 1\n",
    "        \n",
    "        if self.cnt == 2 * self.params.max_memory_size:\n",
    "            n = self.params.max_memory_size\n",
    "            self.memory_states[:n] = self.memory_states[-n:]\n",
    "            self.memory_next_states[:n] = self.memory_next_states[-n:]\n",
    "            self.memory_actions[:n] = self.memory_actions[-n:]\n",
    "            self.memory_rewards[:n] = self.memory_rewards[-n:]\n",
    "            self.cnt = n\n",
    "\n",
    "    def act(self, session, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon / 10:  # Reduce exploration\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(session, state, frame)\n",
    "    \n",
    "    def act_greedy(self, session, state, frame):\n",
    "        act_values = session.run(self.pred, {self.x: [state]})[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, session, batch_size, episode):\n",
    "        if self.cnt < 2000:\n",
    "            return\n",
    "        \n",
    "        cnt = self.cnt\n",
    "        \n",
    "        values = session.run(self.pred, {self.x: self.memory_states[:cnt]})\n",
    "        nextValues = session.run(self.pred, {self.x: self.memory_next_states[:cnt]})\n",
    "        \n",
    "        values[np.arange(cnt), self.memory_actions[:cnt]] = \\\n",
    "            self.memory_rewards[:cnt, 0] + self.params.gamma * np.amax(nextValues, axis=1)\n",
    "\n",
    "        P = np.random.permutation(cnt)\n",
    "        for i in range(0, cnt, batch_size):\n",
    "            batch_indexes = P[i: i + batch_size]\n",
    "            batch_x = self.memory_states[batch_indexes]\n",
    "            batch_y = values[batch_indexes]\n",
    "            _ = session.run(self.train_op, {self.x: batch_x, self.y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-03 14:42:56,027] Making new env: Breakout-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: 4\n",
      "Raw observation space: (210, 160, 3)\n",
      "Max episode steps: 10000\n",
      "Preprocessed observation space: (22400,)\n",
      "Parameters: 22400\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make('CartPole-v1')\n",
    "# env_state_observer = EnvStateObserver(lambda x: x, concat_states_count=3)\n",
    "\n",
    "# env = gym.make('Pong-v0')\n",
    "# env_state_observer = EnvStateObserver(preprocess_input_pong_v0, concat_states_count=4)\n",
    "\n",
    "env = gym.envs.make(\"Breakout-v0\")\n",
    "env_state_observer = EnvStateObserver(preprocess_input_breakout_v0, concat_states_count=4)\n",
    "\n",
    "# env.render(close=True)\n",
    "# plt.imshow(env.render('rgb_array'))\n",
    "sample_state = env_state_observer.env_reset(env)\n",
    "print('Actions: {}'.format(env.action_space.n))\n",
    "print('Raw observation space: {}'.format(env.observation_space.shape))\n",
    "print('Max episode steps: {}'.format(env.spec.max_episode_steps))\n",
    "print('Preprocessed observation space: {}'.format(sample_state.shape))\n",
    "print('Parameters: {}'.format(np.prod(sample_state.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((22400,), 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    22400.000000\n",
       "mean         0.000071\n",
       "std          1.000572\n",
       "min         -0.526482\n",
       "25%         -0.526482\n",
       "50%         -0.526482\n",
       "75%         -0.526482\n",
       "max          2.319368\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOMAAAD8CAYAAACFDhMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0e8d900d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env_state_observer.env_reset(env)\n",
    "state, reward, next_state, done = env_state_observer.env_step(env, 1)\n",
    "print(state.shape, reward)\n",
    "plt.imshow(state.reshape((80, 70, 4))[:,:,3], cmap='Greys')\n",
    "pd.Series(state).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape (22400,), actions 4\n",
      "Loading model checkpoint logs/PolicyGradientAgent/checkpoints/model...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from logs/PolicyGradientAgent/checkpoints/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-03 18:23:58,312] Restoring parameters from logs/PolicyGradientAgent/checkpoints/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1250/25000, reward 1.7, frames 398, exploration rate: 0.86\n",
      "episode: 2500/25000, reward 1.0, frames 213, exploration rate: 0.74\n",
      "episode: 3750/25000, reward 1.6, frames 161, exploration rate: 0.64\n",
      "episode: 5000/25000, reward 1.1, frames 204, exploration rate: 0.55\n",
      "episode: 6250/25000, reward 1.4, frames 267, exploration rate: 0.47\n",
      "episode: 7500/25000, reward 1.1, frames 159, exploration rate: 0.41\n",
      "episode: 8750/25000, reward 0.6, frames 165, exploration rate: 0.35\n",
      "episode: 10000/25000, reward 1.9, frames 417, exploration rate: 0.3\n",
      "episode: 11250/25000, reward 1.2, frames 321, exploration rate: 0.26\n",
      "episode: 12500/25000, reward 0.8, frames 243, exploration rate: 0.22\n",
      "episode: 13750/25000, reward 1.3, frames 203, exploration rate: 0.19\n",
      "episode: 15000/25000, reward 0.9, frames 163, exploration rate: 0.17\n",
      "episode: 16250/25000, reward 1.1, frames 406, exploration rate: 0.14\n",
      "episode: 17500/25000, reward 0.9, frames 329, exploration rate: 0.12\n",
      "episode: 18750/25000, reward 0.8, frames 166, exploration rate: 0.11\n",
      "episode: 20000/25000, reward 0.9, frames 164, exploration rate: 0.091\n",
      "episode: 21250/25000, reward 0.8, frames 165, exploration rate: 0.078\n",
      "episode: 22500/25000, reward 0.9, frames 161, exploration rate: 0.067\n",
      "episode: 23750/25000, reward 1.1, frames 166, exploration rate: 0.058\n",
      "episode: 25000/25000, reward 0.6, frames 155, exploration rate: 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe174559e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "params = LearningParameters(env, env_state_observer.env_reset(env), episodes_count=25000)\n",
    "params.max_frame_in_episode = min(params.max_frame_in_episode, 500)\n",
    "params.epsilon_min = 0.05\n",
    "params.max_memory_size = 2000\n",
    "params.pong_reset_discounted_reward = False\n",
    "agent = PolicyGradientAgent(params)\n",
    "# agent = DqnAgent(params)\n",
    "# agent = ActionAsInputAgent(params)\n",
    "\n",
    "saver = TfSaver('logs/' + agent.__class__.__name__)\n",
    "\n",
    "# Train on GPU\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.7\n",
    "config.operation_timeout_in_ms=60000\n",
    "\n",
    "# Train on CPU\n",
    "# config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "\n",
    "with tf.Session(config=config) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver.load_latest_checkpoint(session)\n",
    "    \n",
    "#     tf_writer = tf.summary.FileWriter('logs/run' + str(run_name), session.graph)\n",
    "\n",
    "    agent, rewards = train_discounted_rewards(session, saver, env, agent, env_state_observer, params,\n",
    "                                              normalize_rewards=True)\n",
    "    # agent, rewards = train_reward_is_time(env, agent, params)\n",
    "    # agent, rewards = train(env, agent, params)\n",
    "    plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 3.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    evaluate(session, env, agent, env_state_observer, params, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOMAAAD8CAYAAACFDhMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe20b4fd9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(config=config) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    show(session, env, agent, env_state_observer, params, 200, width=80, height=70, greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save rewards/model\n",
    "pd.DataFrame(rewards).to_csv('models/rewards_40K_50K.csv', header=None)\n",
    "saver = tf.train.Saver()\n",
    "saver.save(session, 'models/Pong PolicyGradient', global_step=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
