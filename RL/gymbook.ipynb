{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from IPython import display\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from scipy import stats\n",
    "from training_methods import *\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(env, agent, params, frames, width, height, greedy=True):\n",
    "#     img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    state = env_reset(env)\n",
    "    img = plt.imshow(state.reshape(width, height))\n",
    "    frame = 0\n",
    "    for _ in range(frames):\n",
    "#         img.set_data(env.render(mode='rgb_array'))\n",
    "        img.set_data(state.reshape(width, height))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        action = agent.act_greedy(state, frame) if greedy else np.random.randint(0, params.action_size)\n",
    "        state, reward, done, _ = env_step(env, action)\n",
    "        if done:\n",
    "            state = env_reset(env)\n",
    "            frame = 0\n",
    "        else:\n",
    "            frame += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LearningParameters:\n",
    "    def __init__(self, env, episodes_count):\n",
    "        state = env_reset(env)\n",
    "\n",
    "        self.state_shape = state.shape\n",
    "        self.state_size = np.prod(self.state_shape)\n",
    "        self.action_size = env.action_space.n\n",
    "        self.episodes_count = episodes_count\n",
    "        self.max_frame_in_episode = env.spec.max_episode_steps\n",
    "        self.max_memory_size = 10000\n",
    "        self.episodes_between_think = 1\n",
    "        \n",
    "        self.gamma = 0.95                # discount rate\n",
    "        self.epsilon = 1.0               # exploration rate\n",
    "        self.epsilon_start = self.epsilon\n",
    "        self.epsilon_min = 0.0001        # min exploration rate\n",
    "        self.learning_rate = 0.1         # learning rate for algorithm\n",
    "        self.learning_rate_model = 0.01  # learning rate for model\n",
    "        \n",
    "        print(\"State shape {}, actions {}\".format(self.state_shape, self.action_size))\n",
    "\n",
    "    def decay_exploration_rate(self, episode):\n",
    "        # Linear exploration rate decay (lerp)\n",
    "#         self.epsilon = self.epsilon_start - \\\n",
    "#                       (self.epsilon_start - self.epsilon_min) * (float(frame) / self.frames_count)\n",
    "            \n",
    "        # Exponential rate decay\n",
    "        # y(0) = start\n",
    "        # y(1) = start * x\n",
    "        # y(2) = start * x^2\n",
    "        # y(steps) = start * x^steps = min => x = (min/start) ^ (1/steps)\n",
    "        # y(t) = start * x^t\n",
    "        self.epsilon = self.epsilon_start * \\\n",
    "                       math.pow( math.pow(self.epsilon_min / self.epsilon_start, 1.0 / self.episodes_count), episode )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action is added to input as OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionAsInputAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        input_len = self.params.state_size + self.params.action_size\n",
    "\n",
    "        x = tf.placeholder(\"float\", [None, input_len], name=\"Placeholder_x\")\n",
    "        y = tf.placeholder(\"float\", [None, 1], name=\"Placeholder_y\")\n",
    "        \n",
    "        w0 = tf.Variable(tf.random_normal([input_len, 20]))\n",
    "        b0 = tf.Variable(tf.random_normal([20]))\n",
    "        w1 = tf.Variable(tf.random_normal([20, 1]))\n",
    "        b1 = tf.Variable(tf.random_normal([1]))\n",
    "        \n",
    "        h0 = tf.add(tf.matmul(x, w0), b0)\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        pred = tf.add(tf.matmul(h0, w1), b1)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(pred - y)\n",
    "        train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99).minimize(cost)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'pred': pred,\n",
    "            'cost': cost,\n",
    "            'train_op': train_op,\n",
    "            'init': init\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state, frame))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        x = self.model['x']\n",
    "        pred = self.model['pred']\n",
    "\n",
    "        X = np.resize(state, (1, self.params.state_size + self.params.action_size))\n",
    "        X[0, self.params.state_size:] = 0\n",
    "        \n",
    "        rewards = np.zeros((self.params.action_size))\n",
    "        for i in range(self.params.action_size):\n",
    "            X[0, self.params.state_size + i] = 1\n",
    "            rewards[i] = session.run(pred, {x: X})[0]\n",
    "            X[0, self.params.state_size + i] = 0\n",
    "        return np.argmax(rewards)\n",
    "    \n",
    "    def think(self, batch_size):\n",
    "        x = self.model['x']\n",
    "        y = self.model['y']\n",
    "        pred = self.model['pred']\n",
    "        train_op = self.model['train_op']\n",
    "        cost = self.model['cost']\n",
    "        \n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size + self.params.action_size))\n",
    "        Y = np.zeros((cnt, 1))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state, frame = self.memory[i]\n",
    "            inp = np.resize(state, (self.params.state_size + self.params.action_size))\n",
    "            inp[self.params.state_size:] = 0\n",
    "            inp[self.params.state_size + action] = 1\n",
    "            X[i], Y[i] = inp, reward\n",
    "\n",
    "        for e in range(1):\n",
    "            P = np.random.permutation(cnt)\n",
    "            for i in range(0, cnt, batch_size):\n",
    "                batch_indexes = P[i: i + batch_size]\n",
    "                batch_x = X[batch_indexes]\n",
    "                batch_y = Y[batch_indexes]\n",
    "                _ = session.run(train_op, {x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient\n",
    "\n",
    "Run with `params.episodes_between_think = 1`\n",
    "\n",
    "Karpathy: https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
    "\n",
    "TF interpretation: https://gist.github.com/greydanus/5036f784eec2036252e1990da21eda18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyGradientAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        x = tf.placeholder(\"float\", [None, self.params.state_size], name='Placeholder_x')\n",
    "        y = tf.placeholder(\"float\", [None, self.params.action_size], name='Placeholder_y')\n",
    "        \n",
    "        w0 = tf.Variable(tf.random_normal([self.params.state_size, 20]))\n",
    "        b0 = tf.Variable(tf.random_normal([20]))\n",
    "        w1 = tf.Variable(tf.random_normal([20, self.params.action_size]))\n",
    "        b1 = tf.Variable(tf.random_normal([self.params.action_size]))\n",
    "        \n",
    "        h0 = tf.add(tf.matmul(x, w0), b0)\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        pred = tf.add(tf.matmul(h0, w1), b1)\n",
    "#         pred = tf.nn.softmax(pred)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(pred - y)\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.params.learning_rate_model, decay=0.99)\n",
    "#         optimizer = tf.train.AdamOptimizer(learning_rate=self.params.learning_rate_model)\n",
    "    \n",
    "        gradients = optimizer.compute_gradients(cost, var_list=tf.trainable_variables())\n",
    "        train_op = optimizer.apply_gradients(gradients)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'pred': pred,\n",
    "            'cost': cost,\n",
    "            'init': init,\n",
    "            'train_op': train_op\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        x = self.model['x']\n",
    "        pred = self.model['pred']\n",
    "        act_values = session.run(pred, feed_dict={x: [state]})[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        x = self.model['x']\n",
    "        y = self.model['y']\n",
    "        pred = self.model['pred']\n",
    "        train_op = self.model['train_op']\n",
    "        \n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size))\n",
    "        Y = np.zeros((cnt, self.params.action_size))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            target = session.run(pred, feed_dict={x: [state]})[0]\n",
    "            target[action] = reward\n",
    "            X[i], Y[i] = state, target\n",
    "\n",
    "        _ = session.run(train_op, {x: X, y: Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DqnAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        x = tf.placeholder(\"float\", [None, self.params.state_size], name=\"Placeholder_x\")\n",
    "        y = tf.placeholder(\"float\", [None, self.params.action_size], name=\"Placeholder_y\")\n",
    "        \n",
    "        w0 = tf.Variable(tf.random_normal([self.params.state_size, 20]))\n",
    "        b0 = tf.Variable(tf.random_normal([20]))\n",
    "        w1 = tf.Variable(tf.random_normal([20, self.params.action_size]))\n",
    "        b1 = tf.Variable(tf.random_normal([self.params.action_size]))\n",
    "        \n",
    "        h0 = tf.add(tf.matmul(x, w0), b0)\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        pred = tf.add(tf.matmul(h0, w1), b1)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(pred - y)\n",
    "        train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99).minimize(cost)\n",
    "#         train_op = tf.train.AdamOptimizer(learning_rate=self.params.learning_rate_model).minimize(cost)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        return {\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'pred': pred,\n",
    "            'cost': cost,\n",
    "            'init': init,\n",
    "            'train_op': train_op\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        x = self.model['x']\n",
    "        pred = self.model['pred']\n",
    "        act_values = session.run(pred, {x: [state]})[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        x = self.model['x']\n",
    "        y = self.model['y']\n",
    "        pred = self.model['pred']\n",
    "        train_op = self.model['train_op']\n",
    "        cost = self.model['cost']\n",
    "        \n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size))\n",
    "        Y = np.zeros((cnt, self.params.action_size))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            target = session.run(pred, {x: [state]})[0]\n",
    "            target[action] = reward + self.params.gamma * \\\n",
    "                             np.amax(session.run(pred, {x: [next_state]})[0])\n",
    "            X[i], Y[i] = state, target\n",
    "\n",
    "        for e in range(1):\n",
    "            P = np.random.permutation(cnt)\n",
    "            for i in range(0, cnt, batch_size):\n",
    "                batch_indexes = P[i: i + batch_size]\n",
    "                batch_x = X[batch_indexes]\n",
    "                batch_y = Y[batch_indexes]\n",
    "                _ = session.run(train_op, {x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 22:02:22,483] Making new env: Breakout-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: 4, Observation space (210, 160, 3), 100800 parameters\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input_pong_v0(I):\n",
    "    I = I[35:195] # crop\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I = I[::2,::2,0] + I[1::2,::2,0] + I[::2,1::2,0] + I[1::2,1::2,0]\n",
    "    I = I[::2,::2] + I[1::2,::2] + I[::2,1::2] + I[1::2,1::2]\n",
    "    I = I[::2,::2] + I[1::2,::2] + I[::2,1::2] + I[1::2,1::2]\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "def preprocess_input_breakout_v0(I):\n",
    "    I = I[35:195, 10:150]  # crop to (160, 140, 3)\n",
    "    I = (I[:,:,0] + I[:,:,1] + I[:,:,2]) / 3\n",
    "    I = I[::2,::2] + I[1::2,::2] + I[::2,1::2] + I[1::2,1::2]\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "# print(env.spec.max_episode_steps)\n",
    "\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env.my_preprocess_input = lambda x: x\n",
    "\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env.my_preprocess_input = lambda x: x\n",
    "\n",
    "env = gym.make('Breakout-v0')\n",
    "env.my_preprocess_input = preprocess_input_breakout_v0\n",
    "\n",
    "# env.render(close=True)\n",
    "# plt.imshow(env.render('rgb_array'))\n",
    "print('Actions: {}, Observation space {}, {} parameters'.format(\n",
    "    env.action_space.n, env.observation_space.shape, np.prod(env.observation_space.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(210, 160, 3)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(env.spec.max_episode_steps)\n",
    "state = env.reset()\n",
    "env.step(1)\n",
    "# for i in range(10):\n",
    "#     state, reward, _, _ = env.step(1)\n",
    "# state, reward, _, _ = env.step(2)\n",
    "# state, reward, _, _ = env.step(3)\n",
    "# state, reward, _, _ = env.step(3)\n",
    "print(state.shape)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1130db610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOMAAAD8CAYAAACFDhMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113076790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.my_preprocess_input(env.reset())\n",
    "print(state.shape)\n",
    "# prepro(state).reshape((80, 80)).shape\n",
    "plt.imshow(state.reshape((80, 70)), cmap='Greys')\n",
    "# plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape (5600,), actions 4\n",
      "episode: 200/4000, reward 0.0, frames 167, exploration rate: 0.89\n",
      "episode: 400/4000, reward 0.2, frames 164, exploration rate: 0.8\n",
      "episode: 600/4000, reward 0.0, frames 1000, exploration rate: 0.71\n",
      "episode: 800/4000, reward 0.0, frames 1000, exploration rate: 0.63\n",
      "episode: 1000/4000, reward 0.0, frames 1000, exploration rate: 0.56\n",
      "episode: 1200/4000, reward 0.0, frames 1000, exploration rate: 0.5\n",
      "episode: 1400/4000, reward 0.0, frames 1000, exploration rate: 0.45\n",
      "episode: 1600/4000, reward 0.0, frames 1000, exploration rate: 0.4\n",
      "episode: 1800/4000, reward 0.0, frames 1000, exploration rate: 0.36\n",
      "episode: 2000/4000, reward 0.0, frames 1000, exploration rate: 0.32\n",
      "episode: 2200/4000, reward 0.0, frames 1000, exploration rate: 0.28\n",
      "episode: 2400/4000, reward 0.0, frames 1000, exploration rate: 0.25\n",
      "episode: 2600/4000, reward 0.0, frames 1000, exploration rate: 0.22\n",
      "episode: 2800/4000, reward 0.0, frames 1000, exploration rate: 0.2\n",
      "episode: 3000/4000, reward 0.1, frames 1000, exploration rate: 0.18\n",
      "episode: 3200/4000, reward 0.0, frames 1000, exploration rate: 0.16\n",
      "episode: 3400/4000, reward 0.0, frames 1000, exploration rate: 0.14\n",
      "episode: 3600/4000, reward 0.0, frames 1000, exploration rate: 0.13\n",
      "episode: 3800/4000, reward 0.0, frames 1000, exploration rate: 0.11\n",
      "episode: 4000/4000, reward 0.0, frames 1000, exploration rate: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1146a52d0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHWFJREFUeJzt3X+8HXWd3/HXu+GHClQScmUpSUjoZh+KqyK9DfrQrrir\nENAa+6h9NDy2yFptqivt7rq2hdoHWHz08XDFrtbKilFTRFd+KjXdDYbsgkWr/LjR8CNoyCWE5qZA\nQoL8ChCSfPrHmRtPbu65M+fcOWfuzPf9fDzu457znTkzn5k585k53+/MfBURmJlZOv5O1QGYmdlg\nOfGbmSXGid/MLDFO/GZmiXHiNzNLjBO/mVlinPjNzBLjxG9mlhgnfjOzxBxRdQCTmTt3bixcuLDq\nMMzMamP9+vVPRsRQkXFnZOJfuHAhIyMjVYdhZlYbkh4tOq6reszMEuPEb2aWGCd+M7PEOPGbmSXG\nid/MLDG5iV/SfEm3S3pQ0kZJfzTJOJL0JUmjku6TdEbbsAslbc7+Lix7AczMrDtFLufcB/xpRPxM\n0nHAeknrIuLBtnHOBRZnf2cCXwHOlDQHuAwYBiL77OqIeKrUpTAzs8Jyz/gj4rGI+Fn2+lngF8DJ\nE0ZbBlwTLXcCx0s6CTgHWBcRu7Nkvw5YWuoSzAAPPfEsdz+ye2Dze3n/AW4Y2caBA5N3m7ln7z5u\n/vnYwOLpp61PPs+PNz95SNnojme5a8uujp95YPvT3LvtV/zy8WcY2Tq47WL19OyLL/P9DdtLneaP\nNu/k0V3PlzrNMnV1A5ekhcCbgbsmDDoZ2Nb2fiwr61Q+2bRXACsAFixY0E1YlTv7C3cAsPWz7xnI\n/FbesYUr1m5CwD8bnn/Y8Mu+v5Eb148xf/arGF44ZyAx9ctZn/8hcOi6fdefT72+3/vff3zI+0Ft\nF6uni797P399/2Msfs1xnPb3/m4p07zgG3cDM/e7V7hxV9KxwHeBP46IZ8oOJCJWRsRwRAwPDRW6\n6zhZu57bC8DTL7w86fDHn3kRgOf37h9YTGZ19f+efgGAF15OZ38plPglHUkr6f9lRHxvklG2A+2n\nnvOysk7lZmZWkSJX9Qj4BvCLiPjzDqOtBj6YXd3zFuDpiHgMWAucLWm2pNnA2VmZmZlVpEgd/9uA\nC4D7JW3Iyv4jsAAgIq4C1gDnAaPAHuBD2bDdkj4D3JN97vKIcGubmVmFchN/RPwYUM44AXy8w7BV\nwKqeorNpaW0WMysmnf3Fd+7WkKY8DIPyRjCzg1LcW5z4zcwS48RvZpYYJ34zs8Q48ZuZJcaJ38ws\nMU78ZmaJceI3M0uME7+ZWWKc+Gss78bcdO5DNJu+lG50d+Kvobw7DVO8E9GsVyne6e7Eb2aWGCd+\nM7PEOPE3UEJVlWbWAyf+GguneLPSpLQ35T6PX9Iq4L3Ajoj47UmG/zvg99um9zpgKOuEZSvwLLAf\n2BcRw2UFbp2l11RlZt0ocsZ/NbC008CIuCIiTo+I04FLgP89oZetd2bDnfRLJqd4s9KktDflJv6I\nuAMo2l3i+cC104rIzMz6qrQ6fkmvovXL4LttxQHcKmm9pBVlzcvMzHpXpLP1ov4x8H8mVPO8PSK2\nS3oNsE7SL7NfEIfJDgwrABYsWFBiWM2V27ibUmuV2TSltLuUeVXPciZU80TE9uz/DuBmYEmnD0fE\nyogYjojhoaGhEsNqnvw+dwcTh1kTpLi7lJL4Jb0aeAfw/bayYyQdN/4aOBt4oIz5mZlZ74pcznkt\ncBYwV9IYcBlwJEBEXJWN9k+AWyPi+baPngjcnD0H4wjgOxHxg/JCNzOzXuQm/og4v8A4V9O67LO9\nbAvwpl4Ds96l9JRBM+ue79ytMSd4s/KktD858TeQG3fNbCpO/DXmBG9WnpT2Jyd+M7PEOPGbmSXG\nib/G8vvcTai1ymya3LhrM1peH6EJVVWaTVtKdfvjnPjNzBLjxG9mlhgn/gZKqKrSzHrgxF9jTvBm\n5YmEWned+BsowbYqM+uCE3+NOcGblSfvarkmceI3M0uME7+ZWWKc+GssrykqobYqs2lz424bSask\n7ZA0abeJks6S9LSkDdnfpW3DlkraJGlU0sVlBp6yvJrIlOoqzaZLCbaWFTnjvxpYmjPOjyLi9Ozv\ncgBJs4ArgXOB04DzJZ02nWDNzGz6chN/RNwB7O5h2kuA0YjYEhF7geuAZT1Mx8zMSlRWHf9bJd0r\n6RZJr8/KTga2tY0zlpVZn6VUV2lm3cvtbL2AnwGnRMRzks4D/iewuNuJSFoBrABYsGBBCWE1n/O7\nWXlS2p2mfcYfEc9ExHPZ6zXAkZLmAtuB+W2jzsvKOk1nZUQMR8Tw0NDQdMNqtpy2KDfumnUhwd1l\n2olf0m8oyzSSlmTT3AXcAyyWtEjSUcByYPV052ekdWpi1m8J7k+5VT2SrgXOAuZKGgMuA44EiIir\ngA8AH5O0D3gBWB6tSuZ9ki4C1gKzgFURsbEvS5Eon9iblSel3Sk38UfE+TnDvwx8ucOwNcCa3kIz\nM7N+8J27NZbb526CP2HNepXS7uLEX0d5jbuDicKsGRLcYZz4zcwS48RvZpYYJ/4GSqmu0sy658Rf\nY+EUb1aalC6GcOI3M0uME38DJXiRgpl1wYm/xlLsQMKsX1K6E96J38wsMU78NZbXuJtQW5XZtLlx\n18zMGsuJv4by6vZTqqs0m64UdxcnfjOzxDjxN1BKdZVm1j0n/hpzgjcrT0p3wucmfkmrJO2Q9ECH\n4b8v6T5J90v6iaQ3tQ3bmpVvkDRSZuBmZtabImf8VwNLpxj+CPCOiHgD8Blg5YTh74yI0yNiuLcQ\nrVtu3DWzqRTpevEOSQunGP6Ttrd3AvOmH5aZmfVL2XX8HwZuaXsfwK2S1ktaMdUHJa2QNCJpZOfO\nnSWH1Uw+szcrT0qPQMk94y9K0jtpJf63txW/PSK2S3oNsE7SLyPijsk+HxEryaqJhoeH02llmYb8\nPne9Gs2KcuNulyS9Efg6sCwido2XR8T27P8O4GZgSRnzMzOz3k078UtaAHwPuCAiHmorP0bSceOv\ngbOBSa8Msu7kV/Gk85PVbLpSrDLNreqRdC1wFjBX0hhwGXAkQERcBVwKnAD8hVprcF92Bc+JwM1Z\n2RHAdyLiB31YBjMz60KRq3rOzxn+EeAjk5RvAd50+Ces/9KpqzSz7vnO3QZTir9hzSyXE3+D+aoe\nsy4ktLs48ddQ/nm8z/TNikrp+v1xTvw1lNCJiVnfpXT9/jgnfjMzSOqHshO/mVlinPgbLL0fsGbT\nkNAO48RfQ3m/SH0Vp1lxbty1RvBVnGY2FSd+M7PEOPE3WHo/YM2sCCf+Gsu7M9c1PmbFpbS/OPHX\nUF7jrRt3zYpLcX9x4q8hN96alSfF/cmJv8b89E2z8qS0NxVK/JJWSdohadIetNTyJUmjku6TdEbb\nsAslbc7+LiwrcDMz603RM/6rgaVTDD8XWJz9rQC+AiBpDq0eu86k1d/uZZJm9xqsHSq3cTfBn7Bm\nvUppdymU+CPiDmD3FKMsA66JljuB4yWdBJwDrIuI3RHxFLCOqQ8gVkBu4+5gwjBrhBRrTMuq4z8Z\n2Nb2fiwr61TeF5sef5bf+k+3sOOZFzuOc+vGx1m78fHDyv/mwSf4wQOHl9dRU85crrx9tOoQZqSf\nPryLm9aPVR1GrpvWj/HTh3fljhcRfPm2zWx98vlS5z8+3Ud3lTvd6frBA4+z7sEnDr4/cCD4/NpN\nPDFF3irbjGnclbRC0oikkZ07d/Y0jXO+eAd79x3gT2+8t+M4K761nn/9rfWHlX/kmhE++u3Dy60a\nTz73Eles3VR1GDPS+V+7k09O8R2fKT55472c/7U7c8fb+dxLfP7Wh7hg1V2lzn/ns63pfnDV3aVO\nd7o++u31/KtrRg6+//m2p/jy7aN84oYNA4uhrMS/HZjf9n5eVtap/DARsTIihiNieGhoaFrBvLTv\nwLQ+3xR1/gnr9omEZNv6xZfL3W8PHJzu/lKnW7b92WLvHWDeKivxrwY+mF3d8xbg6Yh4DFgLnC1p\ndtaoe3ZW1l+JJI285OjkaXXSr+9r0elWvb8Mcv5HFBlJ0rXAWcBcSWO0rtQ5EiAirgLWAOcBo8Ae\n4EPZsN2SPgPck03q8oiYqpG4FE3vSi3vMbI1PtE/qM6/VqxLfdrWRb9DVX/Xqph/ocQfEefnDA/g\n4x2GrQJWdR+addL0A5slJvEz/SrMmMbdMqW4Ic3Mimpk4k9F1T9RzUpRcVVPr+PXWSMTfyon/Pm/\nbFJZE9YM/fm+Fp1q1TUFg5x9MxN/1Vuwz3Ibdxtw5tKARbCC+tXnbdGpVr2/VDH7Rib+1DX8uGcN\n06+LFbwbdNbIxO8NPs7nzWZ2uEYmfjOrj6qrelLUyMSfSlVH/mImsiKsESq/c7fi/WWQbZPNTPxV\nB9BnKfS5697F0tG3TV30zt2KfxtU8VVvZOI3s/ro24lu088Ap6GZib/hdT0NXzyzgaq6iqcKzUz8\niXBliDVB1VU9vx49nT2qkYk/leN33nL6l4FZcVWf+fvO3WlqesLL73O3/mcu9V8CK2p8W5e926rg\nlKvfXwY//0Ym/tRVfeZi1o3+te16P+ikkYnfG7zFV0Sa2WQKJX5JSyVtkjQq6eJJhn9B0obs7yFJ\nv2obtr9t2Ooygzez+utf267PfDrJ7YFL0izgSuDdwBhwj6TVEfHg+DgR8Sdt4/8b4M1tk3ghIk4v\nL+R8Ta/jH+c+d83KU/X+Msj5FznjXwKMRsSWiNgLXAcsm2L884FrywiuV1VvwH7LO49pwpmOq6nS\nMX6XdtmPLBj/DuVNturv2ky9c/dkYFvb+7Gs7DCSTgEWAbe1Fb9C0oikOyW9v+dIzayR+vWMmqaf\nAE5Hoc7Wu7AcuCki9reVnRIR2yWdCtwm6f6IeHjiByWtAFYALFiwYFpBNH17N335zAZpphwgZtp1\n/NuB+W3v52Vlk1nOhGqeiNie/d8C/JBD6//bx1sZEcMRMTw0NFQgrM6a3gOXWZP064F8VVfhzGRF\nEv89wGJJiyQdRSu5H3Z1jqTXArOBn7aVzZZ0dPZ6LvA24MGJn7X+8OHPzCaTW9UTEfskXQSsBWYB\nqyJio6TLgZGIGD8ILAeui0NPt18HfFXSAVoHmc+2Xw1kvclt3G3AmU4TGqitmP7duVtsulXvL1XM\nvlAdf0SsAdZMKLt0wvtPT/K5nwBvmEZ81gPXdFmd+KnMg9fMO3e9xYFmPe/G7TbNN0Me0lkd98A1\nPX5kQ/15G6aj6qqeFDUy8aciLzn6C29WXEr7SyMTv2sFzOqnf52tOyFM1MjE33g5lyFUfZWCWTdS\nT8v9uo9hKo1M/I3/IiV4BpPgIienX/mvisTai5l2527t+Kdd/XkTpsdVPYPTyMRvLf6+m9lkGpn4\nne/M6qdvT+nsy1TrrZGJv/FqUmdpVkTqCb+KvbmZib8uW7zPfHywOunbUzr7MtXyzbQeuGrHeb/+\nJm5Db9PmS/3Mf5AamfhT4T53zcqT0tU/jUz8KW1As6bo21M6nQ4O08jE33QpPI/f0lF1wq/6Bq+Z\n2tl67fgAb1Y/fXssc01OhAb5RNpCiV/SUkmbJI1KuniS4X8gaaekDdnfR9qGXShpc/Z3YZnBd9L0\nn3YNXzzg8Oo6V981X1Vn/il+t3J74JI0C7gSeDcwBtwjafUkXSheHxEXTfjsHOAyYJjWdl2fffap\nUqK3KfmZ9mY2mSJn/EuA0YjYEhF7geuAZQWnfw6wLiJ2Z8l+HbC0t1CLc8IzM+usSOI/GdjW9n4s\nK5von0q6T9JNkuZ3+VkkrZA0Imlk586dBcJKV02qLM0K6dvD2QqeAFbeuFvBHl1W4+7/AhZGxBtp\nndV/s9sJRMTKiBiOiOGhoaFpBZNgld2kqvhCmVlvZtqdu9uB+W3v52VlB0XEroh4KXv7deAfFP1s\nPzjx15/v3E2QH8s8MEUS/z3AYkmLJB0FLAdWt48g6aS2t+8DfpG9XgucLWm2pNnA2VmZlSDv6+y2\nDrPiUtpbcq/qiYh9ki6ilbBnAasiYqOky4GRiFgN/FtJ7wP2AbuBP8g+u1vSZ2gdPAAuj4jdfVgO\nMzMrKDfxA0TEGmDNhLJL215fAlzS4bOrgFXTiNEmyGuLct2+1UnffpkWvXO3P3MvzHfulsR1emZW\nNzOtcbd2mp72UziuTVzGFJY5dX27c7ei+c5kjUz81uJkaWaTaWTid8Izq5Fqq/iT1MjE33R1edqg\nWR2kuDs1MvH7+vUWHyDM6mOQWauZid95v3F8MLem8uWc1p2cI1ydD4BO9Onp22XYRSdb0Veuiv20\nkYnfKcOsPqruejFFjUz8TZd7Z67r9s0Kq7otzFU9JfGR3szqZpBPHGhk4ndlj5nVRZ07YrEBKtrw\nWevDnx/ZkJzKHtlQ8XerigsZGpn4q96QZlZc1V0vpqiRib/p/Nhls/JU3rjrqp5y+Djf4sODmU2m\nUOKXtFTSJkmjki6eZPgnJD0o6T5JfyvplLZh+yVtyP5WT/xsP/h5/GZmneX2wCVpFnAl8G5gDLhH\n0uqIeLBttJ8DwxGxR9LHgM8B/zwb9kJEnF5y3EaznzNe59itN32r6y844ZTaBIqc8S8BRiNiS0Ts\nBa4DlrWPEBG3R8Se7O2dwLxywzSzpupXwvUP/86KJP6TgW1t78eysk4+DNzS9v4VkkYk3Snp/Z0+\nJGlFNt7Izp07C4TVWdO3d36fu2ZWVNX7SxWNy4U6Wy9K0r8AhoF3tBWfEhHbJZ0K3Cbp/oh4eOJn\nI2IlsBJgeHh4WrnbR3ozq5uZ1ufudmB+2/t5WdkhJL0L+BTwvoh4abw8IrZn/7cAPwTePI14C3Hj\nrplZZ0US/z3AYkmLJB0FLAcOuTpH0puBr9JK+jvaymdLOjp7PRd4G9DeKGw9GD+u5R3f6nwAdGfr\n6elbXX/B4Sl9x3KreiJin6SLgLXALGBVRGyUdDkwEhGrgSuAY4Eb1aqw+r8R8T7gdcBXJR2gdZD5\n7ISrgfoioe1nVntVP4Y/RYXq+CNiDbBmQtmlba/f1eFzPwHeMJ0A7XDjjUFV33Fo1gTju1FK+1Mj\n79z1ob5FKX2TzWpukPcRNDLxO++bmXXWyMRv9Tfx7CeluypT1b87d/sz3bK4z92S1Plqlm40+aoe\nS0f/+tztbsop7S6NTPxNl1dz77p9s+JS3F8amfgTOnCbWUPMtDt3ayeln2xmZt1qZOJvuhSOa75z\nNz3963N36ilX3RbmPndL4itAzOqjX4nXJwudNTLxN116TVFm/ePG3Ybwkd7M6maQaauZib/qAMzM\nZrBGJn5rHh/MzcrTzMSfSJZociN2c5esPFVfjVKWmbIYVcXhRzZYIe5z16w8Ke4vhRK/pKWSNkka\nlXTxJMOPlnR9NvwuSQvbhl2SlW+SdE55oXfW5DNhs3Ez5Uy5NIk+pG3cIH/B5SZ+SbOAK4FzgdOA\n8yWdNmG0DwNPRcRvAl8A/iz77Gm0ump8PbAU+Itsen1Vlw1tZlaFImf8S4DRiNgSEXuB64BlE8ZZ\nBnwze30T8HtqXRy7DLguIl6KiEeA0Wx6ZmZWEeX9vJD0AWBpRHwke38BcGZEXNQ2zgPZOGPZ+4eB\nM4FPA3dGxLez8m8At0TETVPNc3h4OEZGRrpemIUX//XB14tfc+yk42ze8dykwzuVFzGdz/ZifH6d\n5jk+/Nijj+CkV79iIDGV7eX9B9i6a8/B96cOHcOsrHFjfPl+8zXHTlo/275+YHDbZVDyln+mKLpf\ntG/rMrdV0emOx3nCMUcx55ijSpn3VMs+cdiL+/azbfcLACxZOIcbPvrWnuYpaX1EDBcZt1Cfu4Mg\naQWwAmDBggU9TeOtp57AT7fs4sxFczjh2Mk34FN7XmbP3n0sPvHQDfL0Cy/zzIsvH1ZexN79B3h0\n156ePtuLU4eOYe3GJzj7tBM5Ytbhu/682a/k9k07+UeL59a6H9Gtu/Zw3NFH8OxL+3jtbxx3sHzf\ngeCRJ5/ntzqs7/FtOXTc0Yw99cLAtsug7I9gy87Oyz9TPLp7D3NedVSh9b911x7eNP94Tj6+3BOV\nItM96fhXcsdDO1myaE5p+8vmHc9xygmvmnTZdz+/l5f2HThk2LbdL7Bk0RxOnXtMOQHkKJL4twPz\n297Py8omG2dM0hHAq4FdBT8LQESsBFZC64y/SPATXbviLb18zMwsKUXq+O8BFktaJOkoWo21qyeM\nsxq4MHv9AeC2aNUhrQaWZ1f9LAIWA3eXE7qZmfUi94w/IvZJughYC8wCVkXERkmXAyMRsRr4BvAt\nSaPAbloHB7LxbgAeBPYBH4+I/X1aFjMzKyC3cbcKvTbumpmlqpvGXd+5a2aWGCd+M7PEOPGbmSXG\nid/MLDFO/GZmiZmRV/VI2gk82uPH5wJPlhhOWRxXdxxXdxxXd5oY1ykRMVRkxBmZ+KdD0kjRS5oG\nyXF1x3F1x3F1J/W4XNVjZpYYJ34zs8Q0MfGvrDqADhxXdxxXdxxXd5KOq3F1/GZmNrUmnvGbmdkU\nGpP48zqEH8D8t0q6X9IGSSNZ2RxJ6yRtzv7Pzsol6UtZrPdJOqPEOFZJ2pH1ijZe1nUcki7Mxt8s\n6cLJ5lVCXJ+WtD1bZxskndc27JIsrk2SzmkrL3U7S5ov6XZJD0raKOmPsvJK19kUcVW6ziS9QtLd\nku7N4vrPWfkiSXdl87g+e4Q72SPZr8/K75K0MC/ekuO6WtIjbevr9Kx8YN/9bJqzJP1c0l9l7ytd\nX0RE7f9oPS76YeBU4CjgXuC0AcewFZg7oexzwMXZ64uBP8tenwfcAgh4C3BXiXH8DnAG8ECvcQBz\ngC3Z/9nZ69l9iOvTwCcnGfe0bBseDSzKtu2sfmxn4CTgjOz1ccBD2fwrXWdTxFXpOsuW+9js9ZHA\nXdl6uAFYnpVfBXwse/2HwFXZ6+XA9VPF24e4rgY+MMn4A/vuZ9P9BPAd4K+y95Wur6ac8RfpEL4K\n7Z3QfxN4f1v5NdFyJ3C8pJPKmGFE3EGrT4TpxHEOsC4idkfEU8A6YGkf4upkGXBdRLwUEY8Ao7S2\ncenbOSIei4ifZa+fBX4BnEzF62yKuDoZyDrLlnu8U+Mjs78AfhcY70t74voaX483Ab8nSVPEW3Zc\nnQzsuy9pHvAe4OvZe1Hx+mpK4j8Z2Nb2foypd5J+COBWSevV6j8Y4MSIeCx7/ThwYvZ60PF2G8cg\n47so+6m9arw6paq4sp/Vb6Z1tjhj1tmEuKDidZZVW2wAdtBKjA8Dv4qIfZPM4+D8s+FPAycMIq6I\nGF9f/yVbX1+QdPTEuCbMvx/b8YvAvwcOZO9PoOL11ZTEPxO8PSLOAM4FPi7pd9oHRuv3WuWXUM2U\nODJfAf4+cDrwGPBfqwpE0rHAd4E/john2odVuc4miavydRYR+yPidFp9aC8BXjvoGCYzMS5Jvw1c\nQiu+f0ir+uY/DDImSe8FdkTE+kHON09TEn/hTt37JSK2Z/93ADfT2iGeGK/Cyf7vyEYfdLzdxjGQ\n+CLiiWxnPQB8jV//dB1oXJKOpJVc/zIivpcVV77OJotrpqyzLJZfAbcDb6VVVTLelWv7PA7OPxv+\namDXgOJamlWZRUS8BPwPBr++3ga8T9JWWtVsvwv8N6peX702DsykP1p9B2+h1egx3oD1+gHO/xjg\nuLbXP6FVL3gFhzYQfi57/R4ObVi6u+R4FnJoI2pXcdA6M3qEVuPW7Oz1nD7EdVLb6z+hVYcJ8HoO\nbcjaQquRsvTtnC37NcAXJ5RXus6miKvSdQYMAcdnr18J/Ah4L3AjhzZW/mH2+uMc2lh5w1Tx9iGu\nk9rW5xeBz1bx3c+mfRa/btytdn2VsUAz4Y9WK/1DtOobPzXgeZ+abZR7gY3j86dVN/e3wGbgb8a/\nQNmX7cos1vuB4RJjuZZWFcDLtOoBP9xLHMC/pNWANAp8qE9xfSub733Aag5Nap/K4toEnNuv7Qy8\nnVY1zn3AhuzvvKrX2RRxVbrOgDcCP8/m/wBwads+cHe27DcCR2flr8jej2bDT82Lt+S4bsvW1wPA\nt/n1lT8D++63Tfcsfp34K11fvnPXzCwxTanjNzOzgpz4zcwS48RvZpYYJ34zs8Q48ZuZJcaJ38ws\nMU78ZmaJceI3M0vM/wdS20oRzLPOewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1145cdc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = LearningParameters(env, episodes_count=4000)\n",
    "params.max_frame_in_episode = min(params.max_frame_in_episode, 1000)\n",
    "params.epsilon_min = 0.1\n",
    "\n",
    "# agent = PolicyGradientAgent(params)\n",
    "\n",
    "# agent = DqnAgent(params)\n",
    "\n",
    "# agent = ActionAsInputAgent(params)\n",
    "\n",
    "# if 'session' in locals():\n",
    "#     session.close()\n",
    "# session = tf.Session()\n",
    "# session.run(agent.model['init'])\n",
    "\n",
    "agent, rewards = train_discounted_rewards(env, agent, params, normalize_rewards=False)\n",
    "# agent, rewards = train_reward_is_time(env, agent, params)\n",
    "# agent, rewards = train(env, agent, params)\n",
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(env, agent, params, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOMAAAD8CAYAAACFDhMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMIxSIwyj1AjDKDXCMEqNMIxSI/4Pv8rXz6A0mzQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c4b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(env, agent, params, 100, width=80, height=70, greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
