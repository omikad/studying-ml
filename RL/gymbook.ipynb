{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from IPython import display\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from scipy import stats\n",
    "from training_methods import *\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "run_name = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action is added to input as OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionAsInputAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        input_len = self.params.state_size + self.params.action_size\n",
    "\n",
    "        self.x = tf.placeholder(\"float\", [None, input_len], name=\"Placeholder_x\")\n",
    "        self.y = tf.placeholder(\"float\", [None, 1], name=\"Placeholder_y\")\n",
    "\n",
    "        h0 = tf.contrib.layers.fully_connected(\n",
    "            inputs=self.x,\n",
    "            num_outputs=20,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.pred = tf.contrib.layers.fully_connected(\n",
    "            inputs=h0,\n",
    "            num_outputs=1,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.cost = tf.nn.l2_loss(self.pred - self.y)\n",
    "        self.train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99) \\\n",
    "            .minimize(self.cost)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory.append((state, action, reward, next_state, frame))\n",
    "\n",
    "    def act(self, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state, frame)\n",
    "    \n",
    "    def act_greedy(self, state, frame):\n",
    "        X = np.resize(state, (1, self.params.state_size + self.params.action_size))\n",
    "        X[0, self.params.state_size:] = 0\n",
    "        \n",
    "        rewards = np.zeros((self.params.action_size))\n",
    "        for i in range(self.params.action_size):\n",
    "            X[0, self.params.state_size + i] = 1\n",
    "            rewards[i] = session.run(self.pred, {self.x: X})[0]\n",
    "            X[0, self.params.state_size + i] = 0\n",
    "        return np.argmax(rewards)\n",
    "    \n",
    "    def think(self, batch_size, episode):\n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size + self.params.action_size))\n",
    "        Y = np.zeros((cnt, 1))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state, frame = self.memory[i]\n",
    "            inp = np.resize(state, (self.params.state_size + self.params.action_size))\n",
    "            inp[self.params.state_size:] = 0\n",
    "            inp[self.params.state_size + action] = 1\n",
    "            X[i], Y[i] = inp, reward\n",
    "\n",
    "        P = np.random.permutation(cnt)\n",
    "        for i in range(0, cnt, batch_size):\n",
    "            batch_indexes = P[i: i + batch_size]\n",
    "            batch_x = X[batch_indexes]\n",
    "            batch_y = Y[batch_indexes]\n",
    "            _ = session.run(self.train_op, {self.x: batch_x, self.y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient\n",
    "\n",
    "Run with `params.episodes_between_think = 1`\n",
    "\n",
    "Karpathy: https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
    "\n",
    "TF interpretation: https://gist.github.com/greydanus/5036f784eec2036252e1990da21eda18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyGradientAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory_states = []\n",
    "        self.memory_actions = []\n",
    "        self.memory_rewards = []\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.x = tf.placeholder(\"float\", [None, self.params.state_size], name='Placeholder_x')\n",
    "        self.y = tf.placeholder(\"int32\", [None], name='Placeholder_y')\n",
    "        self.r = tf.placeholder(\"float\", [None], name='Placeholder_r')\n",
    "\n",
    "        # Pong:\n",
    "#         x = tf.reshape(self.x, (tf.shape(self.x)[0], 19, 16, 4))\n",
    "#         conv1 = tf.contrib.layers.conv2d(x, 16, 4, 2, activation_fn=tf.nn.relu)\n",
    "#         flattened = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "        # Breakout:\n",
    "        x = tf.reshape(self.x, (tf.shape(self.x)[0], 80, 70, 4))\n",
    "        conv1 = tf.contrib.layers.conv2d(x, 16, 8, 4, activation_fn=tf.nn.relu)\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1, 32, 4, 2, activation_fn=tf.nn.relu)\n",
    "        flattened = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "#         # Cartpole:\n",
    "#         flattened = self.x\n",
    "\n",
    "        fc1 = tf.contrib.layers.fully_connected(flattened, 128,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        fc2 = tf.contrib.layers.fully_connected(\n",
    "            inputs=fc1,\n",
    "            num_outputs=self.params.action_size,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.pred = tf.nn.softmax(fc2)\n",
    "        \n",
    "        actions_ohe = tf.one_hot(self.y, depth=self.params.action_size)\n",
    "        \n",
    "        self.cost = tf.nn.l2_loss(self.pred - actions_ohe)\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.params.learning_rate_model, decay=0.99)\n",
    "    \n",
    "        gradients = optimizer.compute_gradients(\n",
    "            self.cost,\n",
    "            var_list=tf.trainable_variables(),\n",
    "            grad_loss=tf.reshape(self.r, (tf.shape(self.r)[0], 1)))\n",
    "        self.train_op = optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory_states.append(state)\n",
    "        self.memory_actions.append(action)\n",
    "        self.memory_rewards.append(reward)\n",
    "\n",
    "    def act(self, session, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(session, state, frame)\n",
    "    \n",
    "    def act_greedy(self, session, state, frame):\n",
    "        act_values = session.run(self.pred, feed_dict={self.x: [state]})[0]\n",
    "        return np.random.choice(self.params.action_size, p=act_values)\n",
    "\n",
    "    def think(self, session, batch_size, episode):\n",
    "        cnt = len(self.memory_states)\n",
    "\n",
    "        _ = session.run(self.train_op, {\n",
    "            self.x: self.memory_states,\n",
    "            self.y: self.memory_actions,\n",
    "            self.r: self.memory_rewards})\n",
    "        \n",
    "        # It's on-policy algorithm\n",
    "        self.memory_states = [] \n",
    "        self.memory_actions = []\n",
    "        self.memory_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DqnAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory_states = np.zeros((2 * self.params.max_memory_size, self.params.state_size))\n",
    "        self.memory_next_states = np.zeros((2 * self.params.max_memory_size, self.params.state_size))\n",
    "        self.memory_actions = np.zeros((2 * self.params.max_memory_size), dtype=np.int32)\n",
    "        self.memory_rewards = np.zeros((2 * self.params.max_memory_size, 1))\n",
    "        self.cnt = 0\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.x = tf.placeholder(\"float\", [None, self.params.state_size], name=\"Placeholder_x\")\n",
    "        self.y = tf.placeholder(\"float\", [None, self.params.action_size], name=\"Placeholder_y\")\n",
    "\n",
    "        # Pong:\n",
    "#         x = tf.reshape(self.x, (tf.shape(self.x)[0], 19, 16, 4))\n",
    "#         conv1 = tf.contrib.layers.conv2d(x, 16, 4, 2, activation_fn=tf.nn.relu)\n",
    "#         flattened = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "        # Breakout:\n",
    "        x = tf.reshape(self.x, (tf.shape(self.x)[0], 80, 70, 4))\n",
    "        conv1 = tf.contrib.layers.conv2d(x, 16, 8, 4, activation_fn=tf.nn.relu)\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1, 32, 4, 2, activation_fn=tf.nn.relu)\n",
    "        flattened = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Cartpole:\n",
    "#         flattened = self.x\n",
    "\n",
    "        fc1 = tf.contrib.layers.fully_connected(flattened, 128,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        self.pred = tf.contrib.layers.fully_connected(\n",
    "            inputs=fc1,\n",
    "            num_outputs=self.params.action_size,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "#         self.cost = tf.nn.l2_loss(self.pred - self.y)\n",
    "        self.losses = tf.squared_difference(self.pred, self.y)\n",
    "        self.cost = tf.reduce_mean(self.losses)\n",
    "\n",
    "        self.train_op = tf.train.RMSPropOptimizer(learning_rate=self.params.learning_rate, decay=0.99) \\\n",
    "            .minimize(self.cost)\n",
    "#         train_op = tf.train.AdamOptimizer(learning_rate=self.params.learning_rate_model).minimize(cost)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, frame):\n",
    "        self.memory_states[self.cnt] = state\n",
    "        self.memory_next_states[self.cnt] = next_state\n",
    "        self.memory_actions[self.cnt] = action\n",
    "        self.memory_rewards[self.cnt] = reward\n",
    "        self.cnt += 1\n",
    "        \n",
    "        if self.cnt == 2 * self.params.max_memory_size:\n",
    "            n = self.params.max_memory_size\n",
    "            self.memory_states[:n] = self.memory_states[-n:]\n",
    "            self.memory_next_states[:n] = self.memory_next_states[-n:]\n",
    "            self.memory_actions[:n] = self.memory_actions[-n:]\n",
    "            self.memory_rewards[:n] = self.memory_rewards[-n:]\n",
    "            self.cnt = n\n",
    "\n",
    "    def act(self, session, state, frame):\n",
    "        if np.random.rand() <= self.params.epsilon / 10:  # Reduce exploration\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(session, state, frame)\n",
    "    \n",
    "    def act_greedy(self, session, state, frame):\n",
    "        act_values = session.run(self.pred, {self.x: [state]})[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, session, batch_size, episode):\n",
    "        if self.cnt < 2000:\n",
    "            return\n",
    "        \n",
    "        cnt = self.cnt\n",
    "        \n",
    "        values = session.run(self.pred, {self.x: self.memory_states[:cnt]})\n",
    "        nextValues = session.run(self.pred, {self.x: self.memory_next_states[:cnt]})\n",
    "        \n",
    "        values[np.arange(cnt), self.memory_actions[:cnt]] = \\\n",
    "            self.memory_rewards[:cnt, 0] + self.params.gamma * np.amax(nextValues, axis=1)\n",
    "\n",
    "        P = np.random.permutation(cnt)\n",
    "        for i in range(0, cnt, batch_size):\n",
    "            batch_indexes = P[i: i + batch_size]\n",
    "            batch_x = self.memory_states[batch_indexes]\n",
    "            batch_y = values[batch_indexes]\n",
    "            _ = session.run(self.train_op, {self.x: batch_x, self.y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-03 14:42:56,027] Making new env: Breakout-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: 4\n",
      "Raw observation space: (210, 160, 3)\n",
      "Max episode steps: 10000\n",
      "Preprocessed observation space: (22400,)\n",
      "Parameters: 22400\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make('CartPole-v1')\n",
    "# env_state_observer = EnvStateObserver(lambda x: x, concat_states_count=3)\n",
    "\n",
    "# env = gym.make('Pong-v0')\n",
    "# env_state_observer = EnvStateObserver(preprocess_input_pong_v0, concat_states_count=4)\n",
    "\n",
    "env = gym.envs.make(\"Breakout-v0\")\n",
    "env_state_observer = EnvStateObserver(preprocess_input_breakout_v0, concat_states_count=4)\n",
    "\n",
    "# env.render(close=True)\n",
    "# plt.imshow(env.render('rgb_array'))\n",
    "sample_state = env_state_observer.env_reset(env)\n",
    "print('Actions: {}'.format(env.action_space.n))\n",
    "print('Raw observation space: {}'.format(env.observation_space.shape))\n",
    "print('Max episode steps: {}'.format(env.spec.max_episode_steps))\n",
    "print('Preprocessed observation space: {}'.format(sample_state.shape))\n",
    "print('Parameters: {}'.format(np.prod(sample_state.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((22400,), 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    22400.000000\n",
       "mean         0.000071\n",
       "std          1.000572\n",
       "min         -0.526482\n",
       "25%         -0.526482\n",
       "50%         -0.526482\n",
       "75%         -0.526482\n",
       "max          2.319368\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOMAAAD8CAYAAACFDhMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0e8d900d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env_state_observer.env_reset(env)\n",
    "state, reward, next_state, done = env_state_observer.env_step(env, 1)\n",
    "print(state.shape, reward)\n",
    "plt.imshow(state.reshape((80, 70, 4))[:,:,3], cmap='Greys')\n",
    "pd.Series(state).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape (22400,), actions 4\n",
      "Loading model checkpoint logs/PolicyGradientAgent/checkpoints/model...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from logs/PolicyGradientAgent/checkpoints/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-03 21:19:19,528] Restoring parameters from logs/PolicyGradientAgent/checkpoints/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5000/100000, reward 1.3, frames 174, exploration rate: 0.86\n",
      "episode: 10000/100000, reward 0.9, frames 164, exploration rate: 0.74\n",
      "episode: 15000/100000, reward 1.3, frames 225, exploration rate: 0.64\n",
      "episode: 20000/100000, reward 1.3, frames 354, exploration rate: 0.55\n",
      "episode: 25000/100000, reward 0.7, frames 169, exploration rate: 0.47\n",
      "episode: 30000/100000, reward 1.4, frames 201, exploration rate: 0.41\n",
      "episode: 35000/100000, reward 1.1, frames 284, exploration rate: 0.35\n",
      "episode: 40000/100000, reward 1.1, frames 206, exploration rate: 0.3\n",
      "episode: 45000/100000, reward 1.8, frames 301, exploration rate: 0.26\n",
      "episode: 50000/100000, reward 1.2, frames 259, exploration rate: 0.22\n",
      "episode: 55000/100000, reward 2.0, frames 229, exploration rate: 0.19\n",
      "episode: 60000/100000, reward 1.3, frames 161, exploration rate: 0.17\n",
      "episode: 65000/100000, reward 0.3, frames 162, exploration rate: 0.14\n",
      "episode: 70000/100000, reward 0.6, frames 201, exploration rate: 0.12\n",
      "episode: 75000/100000, reward 1.3, frames 332, exploration rate: 0.11\n",
      "episode: 80000/100000, reward 1.0, frames 265, exploration rate: 0.091\n",
      "episode: 85000/100000, reward 1.4, frames 161, exploration rate: 0.078\n",
      "episode: 90000/100000, reward 0.9, frames 154, exploration rate: 0.067\n",
      "episode: 95000/100000, reward 0.4, frames 261, exploration rate: 0.058\n",
      "episode: 100000/100000, reward 0.6, frames 157, exploration rate: 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJyIyBBM6EZEhmNCJiAzx/7jTUGWIvCnYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe17c70ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "params = LearningParameters(env, env_state_observer.env_reset(env), episodes_count=100000)\n",
    "params.max_frame_in_episode = min(params.max_frame_in_episode, 500)\n",
    "params.epsilon_min = 0.05\n",
    "params.max_memory_size = 2000\n",
    "params.pong_reset_discounted_reward = False\n",
    "agent = PolicyGradientAgent(params)\n",
    "# agent = DqnAgent(params)\n",
    "# agent = ActionAsInputAgent(params)\n",
    "\n",
    "saver = TfSaver('logs/' + agent.__class__.__name__)\n",
    "\n",
    "# Train on GPU\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.7\n",
    "config.operation_timeout_in_ms=60000\n",
    "\n",
    "# Train on CPU\n",
    "# config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "\n",
    "with tf.Session(config=config) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver.load_latest_checkpoint(session)\n",
    "    \n",
    "#     tf_writer = tf.summary.FileWriter('logs/run' + str(run_name), session.graph)\n",
    "\n",
    "    agent, rewards = train_discounted_rewards(session, saver, env, agent, env_state_observer, params,\n",
    "                                              normalize_rewards=True)\n",
    "    # agent, rewards = train_reward_is_time(env, agent, params)\n",
    "    # agent, rewards = train(env, agent, params)\n",
    "    plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    evaluate(session, env, agent, env_state_observer, params, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOMAAAD8CAYAAACFDhMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYZQaYRilRhhGqRGGUWqEYZQa8X/oq9gdD81swgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0e8d30ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(config=config) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    show(session, env, agent, env_state_observer, params, 200, width=80, height=70, greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save rewards/model\n",
    "pd.DataFrame(rewards).to_csv('models/rewards_40K_50K.csv', header=None)\n",
    "saver = tf.train.Saver()\n",
    "saver.save(session, 'models/Pong PolicyGradient', global_step=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
