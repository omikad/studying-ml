{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from IPython.display import display\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from matplotlib import animation\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LearningParameters:\n",
    "    def __init__(self, state_size, action_size, episodes_count):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.episodes_count = episodes_count\n",
    "        self.max_memory_size = 10000\n",
    "        self.episodes_between_think = 5\n",
    "        \n",
    "        self.gamma = 0.95                # discount rate\n",
    "        self.epsilon = 1.0               # exploration rate\n",
    "        self.epsilon_start = self.epsilon\n",
    "        self.epsilon_min = 0.0001        # min exploration rate\n",
    "        self.learning_rate = 0.1         # learning rate for algorithm\n",
    "        self.learning_rate_model = 0.01  # learning rate for model (Adam optimizer)\n",
    "\n",
    "    def decay_exploration_rate(self, episode):\n",
    "        # Linear exploration rate decay (lerp)\n",
    "#         self.epsilon = self.epsilon_start - \\\n",
    "#                       (self.epsilon_start - self.epsilon_min) * (float(frame) / self.frames_count)\n",
    "            \n",
    "        # Exponential rate decay\n",
    "        # y(0) = start\n",
    "        # y(1) = start * x\n",
    "        # y(2) = start * x^2\n",
    "        # y(steps) = start * x^steps = min => x = (min/start) ^ (1/steps)\n",
    "        # y(t) = start * x^t\n",
    "        self.epsilon = self.epsilon_start * \\\n",
    "                       math.pow( math.pow(self.epsilon_min / self.epsilon_start, 1.0 / self.episodes_count), episode )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_reward_is_discounted_predicted(env, agent, params):\n",
    "    rewards = []\n",
    "    \n",
    "    all_replays = []\n",
    "    \n",
    "    for episode in range(params.episodes_count):\n",
    "        state = np.reshape(env.reset(), [1, params.state_size])        \n",
    "        frame = 0\n",
    "        \n",
    "        replays = []\n",
    "        \n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            next_state, _, done, _ = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, params.state_size])\n",
    "    \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            replays.append((state, action, next_state))\n",
    "            frame += 1\n",
    "            state = next_state\n",
    "            \n",
    "        all_replays.append(replays)\n",
    "            \n",
    "        rewards.append(len(replays))\n",
    "            \n",
    "        if (episode + 1) % (params.episodes_count / 20) == 0:\n",
    "            print(\"episode: {}/{}, reward {}, exploration rate: {:.2}\"\n",
    "              .format(episode + 1, params.episodes_count, np.mean(rewards[-10:]), params.epsilon))\n",
    "            \n",
    "        if (episode + 1) % params.episodes_between_think == 0:\n",
    "            agent.memory.clear()\n",
    "            for replays in all_replays:\n",
    "                reward_value = 0\n",
    "                for index in reversed(range(len(replays))):\n",
    "                    state, action, next_state = replays[index]\n",
    "                    reward_value = reward_value * params.gamma + agent.model.predict(state)[0][action]\n",
    "                    agent.remember(state, action, reward_value, next_state)\n",
    "            agent.think(32)\n",
    "        \n",
    "        params.decay_exploration_rate(episode)\n",
    "\n",
    "    return agent, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action is added to input as OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionAsInputAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim=self.params.state_size + self.params.action_size, activation='relu'))\n",
    "#         model.add(Dense(20, activation='relu', kernel_initializer='uniform'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.params.learning_rate_model))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state)\n",
    "    \n",
    "    def act_greedy(self, state):\n",
    "        X = np.resize(state[0], (1, self.params.state_size + self.params.action_size))\n",
    "        X[0, self.params.state_size:] = 0\n",
    "        rewards = np.zeros((self.params.action_size))\n",
    "        for i in range(self.params.action_size):\n",
    "            X[0, self.params.state_size + i] = 1\n",
    "            rewards[i] = self.model.predict(X)[0]\n",
    "            X[0, self.params.state_size + i] = 0\n",
    "        return np.argmax(rewards)\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size + self.params.action_size))\n",
    "        Y = np.zeros((cnt, 1))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            state = np.resize(state[0], (self.params.state_size + self.params.action_size))\n",
    "            state[self.params.state_size:] = 0\n",
    "            state[self.params.state_size + action] = 1\n",
    "            X[i], Y[i] = state, reward\n",
    "        self.model.fit(X, Y, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient\n",
    "* Doesn't work with if predict immediate reward (method `train`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyGradientAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "        X = np.random.uniform(-1.0, 1.0, (5000, self.params.state_size))\n",
    "        Y = np.random.uniform(-0.0001, 0.0001, (5000, self.params.action_size))\n",
    "        self.model.fit(X, Y, epochs=1, verbose=0)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim=self.params.state_size, activation='relu'))\n",
    "#         model.add(Dense(20, activation='relu', kernel_initializer='uniform'))\n",
    "        model.add(Dense(self.params.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.params.learning_rate_model))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state)\n",
    "    \n",
    "    def act_greedy(self, state):\n",
    "        act_values = self.model.predict(state)[0]\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size))\n",
    "        Y = np.zeros((cnt, self.params.action_size))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            target = self.model.predict(state)[0]\n",
    "            target[action] = reward\n",
    "            X[i], Y[i] = state, target\n",
    "        self.model.fit(X, Y, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.memory = deque(maxlen=self.params.max_memory_size)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.params.state_size, activation='relu'))\n",
    "#         model.add(Dense(20, activation='relu', kernel_initializer='uniform'))\n",
    "        model.add(Dense(self.params.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.params.learning_rate_model))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.params.epsilon:\n",
    "            return np.random.randint(0, self.params.action_size)\n",
    "        return self.act_greedy(state)\n",
    "    \n",
    "    def act_greedy(self, state):\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def think(self, batch_size):\n",
    "        cnt = len(self.memory)\n",
    "        X = np.zeros((cnt, self.params.state_size))\n",
    "        Y = np.zeros((cnt, self.params.action_size))\n",
    "        for i in range(cnt):\n",
    "            state, action, reward, next_state = self.memory[i]\n",
    "            target = self.model.predict(state)[0]\n",
    "            target[action] = reward + self.params.gamma * \\\n",
    "                            np.amax(self.model.predict(next_state)[0])\n",
    "            X[i], Y[i] = state, target\n",
    "        self.model.fit(X, Y, batch_size=batch_size, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_reward_is_time(env, agent, params):\n",
    "    \"\"\"Ignore reward from the env, agent will be trained to increase total time played\"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    all_replays = []\n",
    "    \n",
    "    for episode in range(params.episodes_count):\n",
    "        state = np.reshape(env.reset(), [1, params.state_size])        \n",
    "        frame = 0\n",
    "        \n",
    "        states = []\n",
    "        replays = []\n",
    "        \n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            next_state, _, done, _ = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, params.state_size])\n",
    "    \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            states.append(state[0])\n",
    "            replays.append((state, action, next_state))\n",
    "            frame += 1\n",
    "            state = next_state\n",
    "        \n",
    "#         states = np.array(states)\n",
    "#         predicted = agent.model.predict(states)\n",
    "#         reward_value = 0.0\n",
    "#         for index in reversed(range(len(replays))):\n",
    "#             state, action, next_state = replays[index]\n",
    "#             reward_value = reward_value * params.gamma + predicted[index, action]\n",
    "#             agent.remember(state, action, reward_value, next_state)\n",
    "        \n",
    "        for index, replay in enumerate(replays):\n",
    "            state, action, next_state = replay\n",
    "            reward_value = len(replays) - index\n",
    "            agent.remember(state, action, reward_value, next_state)\n",
    "            \n",
    "        rewards.append(len(replays))\n",
    "            \n",
    "        if (episode + 1) % (params.episodes_count / 20) == 0:\n",
    "            print(\"episode: {}/{}, reward {}, exploration rate: {:.2}\"\n",
    "              .format(episode + 1, params.episodes_count, np.mean(rewards[-10:]), params.epsilon))\n",
    "            \n",
    "        if (episode + 1) % params.episodes_between_think == 0:\n",
    "            agent.think(32)\n",
    "        \n",
    "        params.decay_exploration_rate(episode)\n",
    "\n",
    "    return agent, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(env, agent, params):   \n",
    "    rewards = []\n",
    "    \n",
    "    for episode in range(params.episodes_count):\n",
    "        state = np.reshape(env.reset(), [1, params.state_size])        \n",
    "        frame = 0\n",
    "        \n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, params.state_size])\n",
    "    \n",
    "            if done:\n",
    "                reward = -10\n",
    "    \n",
    "            if frame < env.spec.max_episode_steps:\n",
    "                agent.remember(state, action, reward, next_state)\n",
    "                \n",
    "            frame += 1\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        rewards.append(frame)\n",
    "            \n",
    "        if (episode + 1) % (params.episodes_count / 20) == 0:\n",
    "            print(\"episode: {}/{}, reward {}, exploration rate: {:.2}\"\n",
    "              .format(episode + 1, params.episodes_count, np.mean(rewards[-10:]), params.epsilon))\n",
    "            \n",
    "        if (episode + 1) % params.episodes_between_think == 0:\n",
    "            agent.think(32)\n",
    "        \n",
    "        params.decay_exploration_rate(episode)\n",
    "\n",
    "    return agent, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(env, agent, params, render, frames):\n",
    "    state = env.reset()\n",
    "    render_frames = []\n",
    "    for e in range(frames):\n",
    "        if render:\n",
    "            render_frames.append(env.render(mode = 'rgb_array'))\n",
    "        state = np.reshape(state, [1, params.state_size])\n",
    "        action = agent.act_greedy(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done or e == frames - 1:\n",
    "            print(\"score: {}\"\n",
    "                  .format(e))\n",
    "            break\n",
    "\n",
    "    if render:\n",
    "        env.render(close=True)\n",
    "        display_frames_as_gif(render_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# env.render(close=True)\n",
    "print(env.spec.max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-18 12:34:34,069] Making new env: CartPole-v1\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5/100, reward 28.8, exploration rate: 0.76\n",
      "episode: 10/100, reward 27.6, exploration rate: 0.48\n",
      "episode: 15/100, reward 21.8, exploration rate: 0.3\n",
      "episode: 20/100, reward 14.0, exploration rate: 0.19\n",
      "episode: 25/100, reward 9.7, exploration rate: 0.12\n",
      "episode: 30/100, reward 9.0, exploration rate: 0.076\n",
      "episode: 35/100, reward 9.9, exploration rate: 0.048\n",
      "episode: 40/100, reward 9.9, exploration rate: 0.03\n",
      "episode: 45/100, reward 9.0, exploration rate: 0.019\n",
      "episode: 50/100, reward 110.3, exploration rate: 0.012\n",
      "episode: 55/100, reward 125.0, exploration rate: 0.0076\n",
      "episode: 60/100, reward 49.2, exploration rate: 0.0048\n",
      "episode: 65/100, reward 58.5, exploration rate: 0.003\n",
      "episode: 70/100, reward 196.4, exploration rate: 0.0019\n",
      "episode: 75/100, reward 375.8, exploration rate: 0.0012\n",
      "episode: 80/100, reward 448.7, exploration rate: 0.00076\n",
      "episode: 85/100, reward 468.9, exploration rate: 0.00048\n",
      "episode: 90/100, reward 428.8, exploration rate: 0.0003\n",
      "episode: 95/100, reward 313.1, exploration rate: 0.00019\n",
      "episode: 100/100, reward 344.7, exploration rate: 0.00012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x129f776d0>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d5c9dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = LearningParameters(env.observation_space.shape[0], env.action_space.n, 100)\n",
    "# trained_agent, rewards = train_reward_is_time(env, PolicyGradientAgent(params), params)\n",
    "# trained_agent, rewards = train(env, DQNAgent(params), params)\n",
    "trained_agent, rewards = train_reward_is_time(env, ActionAsInputAgent(params), params)\n",
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 499\n"
     ]
    }
   ],
   "source": [
    "evaluate(env, trained_agent, params, False, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
